{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ссылки на страницы\n",
    "num_of_page = 50\n",
    "url_sp = []\n",
    "for i in range(num_of_page):\n",
    "    # получаем ссылки на каждую страницу\n",
    "    url = 'https://nn.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&p=' + str(i + 1) + '&region=4885&room3=1'\n",
    "    \n",
    "    #response = requests.get(url, headers=headers, verify=False)\n",
    "    #print(response)\n",
    "    \n",
    "    url_sp.append(url)\n",
    "# url_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# получаем список ссылок на каждую квартиру на каждой странице\n",
    "list_hreff = []\n",
    "for u in url_sp:\n",
    "    response = requests.get(u, headers=headers, verify=False)\n",
    "    response.encoding = 'utf8'\n",
    "    content = response.text\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    \n",
    "    box = soup.find_all(class_='_93444fe79c--media--9P6wN')\n",
    "    links = [link['href'] for link in box]\n",
    "    for l in links:\n",
    "        list_hreff.append(l)\n",
    "# list_hreff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# переходим по ссылке на каждую квартиру и собираем инфу\n",
    "result_df1 = pd.DataFrame()\n",
    "for l in list_hreff:\n",
    "    r = requests.get(l, headers=headers, verify=False)\n",
    "    r.encoding = 'utf-8'\n",
    "    content = r.text\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    \n",
    "    # заголовок\n",
    "    title = soup.find('h1', class_='a10a3f92e9--title--vlZwT').get_text()\n",
    "    \n",
    "    # заголовок 2\n",
    "    title2 = soup.find('title').get_text()\n",
    "    \n",
    "    # цена\n",
    "    price = soup.find_all('span', class_='a10a3f92e9--color_black_100--kPHhJ a10a3f92e9--lineHeight_9u--qr919 a10a3f92e9--fontWeight_bold--ePDnv a10a3f92e9--fontSize_28px--xlUV0 a10a3f92e9--display_block--pDAEx a10a3f92e9--text--g9xAG')[-1].get_text().replace(u'\\xa0', u' ')\n",
    "    price = re.sub(r'[₽\\s]', '', price).strip()\n",
    "    \n",
    "    # застройщик\n",
    "    developer_el = soup.find('ul', class_='a10a3f92e9--container--z1RwI')\n",
    "    if developer_el is not None: # проверяем, что элемент существует\n",
    "        developer = developer_el.find('a', class_='a10a3f92e9--element--hhgQA').get_text() # получаем текст из элемента\n",
    "    else:\n",
    "        developer = 'No information' \n",
    "    \n",
    "    # ссылка на квартиру\n",
    "    link = soup.find(\"meta\", attrs = {\"property\":\"og:url\"})['content']\n",
    "    \n",
    "    # описание от собственника\n",
    "    descriptoin = soup.find('span', class_='a10a3f92e9--color_black_100--kPHhJ a10a3f92e9--lineHeight_6u--A1GMI a10a3f92e9--fontWeight_normal--P9Ylg a10a3f92e9--fontSize_16px--RB9YW a10a3f92e9--display_block--pDAEx a10a3f92e9--text--g9xAG a10a3f92e9--text_letterSpacing__0--mdnqq a10a3f92e9--text_whiteSpace__pre-wrap--scZwb').get_text()\n",
    "    \n",
    "    # площадь\n",
    "    square = soup.find('span', class_='a10a3f92e9--color_black_100--kPHhJ a10a3f92e9--lineHeight_6u--A1GMI a10a3f92e9--fontWeight_bold--ePDnv a10a3f92e9--fontSize_16px--RB9YW a10a3f92e9--display_block--pDAEx a10a3f92e9--text--g9xAG').get_text().replace(u'\\xa0', u' ')\n",
    "    square = re.sub(r'м²', '', square).strip()\n",
    "    square = re.sub(r',', '.', square) \n",
    "    \n",
    "    # цена за 1 кв м\n",
    "    price_one_metr = round(int(price)/float(square))\n",
    "    \n",
    "    # ЖК\n",
    "    gk_element = soup.find('a', class_ = 'a10a3f92e9--link--A5SdC')\n",
    "    if gk_element is not None: # проверяем, что элемент существует\n",
    "        gk = gk_element.get_text() # получаем текст из элемента\n",
    "    else:\n",
    "        gk = 'No information'\n",
    "    \n",
    "    # адрес\n",
    "    adr = soup.find_all(\"span\", attrs = {\"itemprop\":\"name\"})[-1]['content']\n",
    "    \n",
    "    # этаж\n",
    "    etage = soup.find('span', text = re.compile(' из '), attrs = {'class' : 'a10a3f92e9--color_black_100--kPHhJ a10a3f92e9--lineHeight_6u--A1GMI a10a3f92e9--fontWeight_bold--ePDnv a10a3f92e9--fontSize_16px--RB9YW a10a3f92e9--display_block--pDAEx a10a3f92e9--text--g9xAG'}).get_text()\n",
    "    \n",
    "    new_row = {'Цена': price, 'Цена за 1 кв.м': price_one_metr, 'Заголовок': title, 'Заголовок_2': title2,\n",
    "                'Застройщик':developer, 'ЖК':gk, 'Ссылка': link, 'Описание':descriptoin, 'Площадь':square,\n",
    "                'Адрес':adr, 'Этаж': etage}\n",
    "    \n",
    "    result_df1 = result_df1.append(new_row, ignore_index=True)\n",
    "    #result_df1.to_excel('трешки.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
